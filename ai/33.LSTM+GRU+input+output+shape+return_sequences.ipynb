{"cells":[{"cell_type":"markdown","metadata":{"id":"UFm4zEmdF3HZ"},"source":["# 020. LSTM/GRU input/output shape\n","\n","- return_sequences = False, True 일 때의 output 비교\n","\n","- return_state = False, True 일 때의 internal state output 비교\n","\n","- Bidirectional LSTM/GRU 의 output 비교"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z5bhMKuKF3Hd","outputId":"cbe67783-5f83-4de9-d0ea-b139bbb9c921","executionInfo":{"status":"ok","timestamp":1753853496821,"user_tz":-540,"elapsed":9205,"user":{"displayName":"정지영","userId":"13241255153185821332"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["(2, 5, 1)\n"]}],"source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Bidirectional, GRU\n","import numpy as np\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","B = 2   # batch size\n","T = 5   #Time Steps\n","D = 1   #features\n","U = 3   #LSTM units\n","\n","X = np.random.randn(B, T, D)\n","print(X.shape)"]},{"cell_type":"markdown","metadata":{"id":"93BtygLbF3Hg"},"source":["# LSTM\n","\n","## return_sequences\n","\n","- False (default) - last time step 의 output 만 반환\n","- True - 모든 timestep 의 output 을 모두 반환"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BUOMaX3mF3Hg","outputId":"57d79a62-c572-45cb-b604-694b4e9c651f","executionInfo":{"status":"ok","timestamp":1753853503145,"user_tz":-540,"elapsed":902,"user":{"displayName":"정지영","userId":"13241255153185821332"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["---- return_sequences=False ----> last timestep 의 output 만 반환\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step\n","(2, 3)\n","[[ 0.09391557  0.01567914 -0.05843095]\n"," [-0.07300735 -0.02361687  0.01637033]]\n","\n","---- return_sequences=True ----> 모든 timestep 별 output 출력\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n","(2, 5, 3)\n","[[[-4.39144485e-03  1.18200649e-02  6.55261129e-02]\n","  [-5.14554232e-03  1.96261052e-02  9.63263661e-02]\n","  [-4.75443900e-03  2.52968855e-02  1.11715764e-01]\n","  [-2.54300260e-03  2.58843284e-02  1.02124199e-01]\n","  [-3.53531516e-03  3.18513066e-02  1.21536471e-01]]\n","\n"," [[ 2.32938954e-04 -7.73716776e-04 -4.20006830e-03]\n","  [ 5.43427328e-03 -2.41574235e-02 -1.15892574e-01]\n","  [ 7.93969724e-03 -4.84143458e-02 -2.04264283e-01]\n","  [ 6.22138474e-03 -5.56628816e-02 -1.94290519e-01]\n","  [ 1.99340750e-04 -4.43463139e-02 -1.03066772e-01]]]\n"]}],"source":["def lstm(return_sequences=False):\n","    inp = Input(shape=(T, D))\n","    out = LSTM(U, return_sequences=return_sequences)(inp)\n","\n","    model = Model(inputs=inp, outputs=out)\n","    return model.predict(X)\n","\n","print(\"---- return_sequences=False ----> last timestep 의 output 만 반환\")\n","lstm_out = lstm(return_sequences=False)\n","print(lstm_out.shape)\n","print(lstm_out)\n","\n","print(\"\\n---- return_sequences=True ----> 모든 timestep 별 output 출력\")\n","lstm_out = lstm(return_sequences=True)\n","print(lstm_out.shape)\n","print(lstm_out)"]},{"cell_type":"markdown","metadata":{"id":"HOz77oSnF3Hh"},"source":["## return_state\n","\n","- False (default) - output 만 반환\n","\n","- True - output, last step 의 hidden state, cell state (LSTM 의 경우) 반환"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"js8LLdQXF3Hi","outputId":"4846ea63-fa5b-4522-a229-a4b7fca204e2","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["---- return_state=False ----> outout only\n","o : (2, 3)\n","[[ 0.08662598  0.03549024 -0.16302542]\n"," [-0.04423545 -0.08543726  0.14413275]]\n","\n","---- return_state=True ----> outout, hidden state, cell state all\n","o : (2, 3)\n","[[-0.08016161 -0.03315075  0.04808342]\n"," [ 0.14247695  0.17282172 -0.18928523]]\n","h : (2, 3)\n","[[-0.08016161 -0.03315075  0.04808342]\n"," [ 0.14247695  0.17282172 -0.18928523]]\n","c : (2, 3)\n","[[-0.1397419  -0.09048831  0.12727761]\n"," [ 0.3231544   0.32186234 -0.33606148]]\n"]}],"source":["def lstm(return_state=False):\n","    inp = Input(shape=(T, D))\n","    out = LSTM(U, return_state=return_state)(inp)\n","\n","    model = Model(inputs=inp, outputs=out)\n","\n","    if return_state:\n","        o, h, c = model.predict(X)\n","        print(\"o :\", o.shape)\n","        print(o)\n","        print(\"h :\", h.shape)\n","        print(h)\n","        print(\"c :\", c.shape)\n","        print(c)\n","    else:\n","        o = model.predict(X)\n","        print(\"o :\", o.shape)\n","        print(o)\n","\n","print(\"---- return_state=False ----> outout only\")\n","lstm(return_state=False)\n","print(\"\\n---- return_state=True ----> outout, hidden state, cell state all\")\n","lstm(return_state=True)"]},{"cell_type":"markdown","metadata":{"id":"Lzhij_1jF3Hj"},"source":["# Bidirectional LSTM\n","\n","- 순방향, 역방향이 concatenate 된 output 출력  \n","\n","- hidden state, cell state 는 순방향, 역방향 별도 출력"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qHWIut5EF3Hj","outputId":"ee8b023b-e1be-463c-a6f4-6c78017e2f31"},"outputs":[{"data":{"text/plain":["(5, 1, 3)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["T, D, U"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xRfP9p7aF3Hk","outputId":"b745662b-86a1-4f1c-ffde-42bc1e5a43c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["*** 순방향, 역방향이 concatenate ***\n","---- return_sequences=False ----> last timestep 의 output 만 반환\n","WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4c09c7d680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","o : (2, 6)\n","\n","---- return_sequences=True ----> 모든 timestep 별 output 출력\n","WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4c09db30e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","o : (2, 5, 6)\n","\n","---- return_sequences=True, return_state=True\n","o : (2, 6)\n","h1 : (2, 3)\n","c1 : (2, 3)\n","h2 : (2, 3)\n","c2 : (2, 3)\n"]}],"source":["def bi_lstm(return_sequences=False, return_state=False):\n","    inp = Input(shape=(T, D))\n","    out = Bidirectional(\n","            LSTM(U, return_state=return_state, return_sequences=return_sequences))(inp)\n","\n","    model = Model(inputs=inp, outputs=out)\n","\n","    if return_state:\n","        o, h1, c1, h2, c2 = model.predict(X)\n","        print(\"o :\",o.shape)\n","        print(\"h1 :\", h1.shape)\n","        print(\"c1 :\", c1.shape)\n","        print(\"h2 :\", h2.shape)\n","        print(\"c2 :\", c2.shape)\n","    else:\n","        o = model.predict(X)\n","        print(\"o :\", o.shape)\n","\n","print(\"*** 순방향, 역방향이 concatenate ***\")\n","print(\"---- return_sequences=False ----> last timestep 의 output 만 반환\")\n","bi_lstm(return_sequences=False, return_state=False)\n","print()\n","print(\"---- return_sequences=True ----> 모든 timestep 별 output 출력\")\n","bi_lstm(return_sequences=True)\n","print()\n","print(\"---- return_sequences=True, return_state=True\")\n","bi_lstm(return_state=True)"]},{"cell_type":"markdown","metadata":{"id":"0CZeBf5dF3Hm"},"source":["# GRU\n","\n","- cell state 가 없는 것만 LSTM 과 차이"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wkKrSkgQF3Hm","outputId":"fac0600f-d4ee-4322-a856-cb76e769f6e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["---- Many-to-One output ----\n","o : (2, 3)\n","\n","---- Many-to-Many output ----\n","o : (2, 5, 3)\n","\n","---- Sequence-to-Vector output ----\n","o : (2, 3)\n","h : (2, 3)\n"]}],"source":["def gru(return_sequences=False, return_state=False):\n","    inp = Input(shape=(T, D))\n","    out = GRU(U, return_state=return_state, return_sequences=return_sequences)(inp)\n","\n","    model = Model(inputs=inp, outputs=out)\n","\n","    if return_state:\n","        o, h = model.predict(X)\n","        print(\"o :\", o.shape)\n","        print(\"h :\", h.shape)\n","    else:\n","        o = model.predict(X)\n","        print(\"o :\", o.shape)\n","\n","print(\"---- Many-to-One output ----\")\n","gru(return_sequences=False, return_state=False)\n","print()\n","print(\"---- Many-to-Many output ----\")\n","gru(return_sequences=True)\n","print()\n","print(\"---- Sequence-to-Vector output ----\")\n","gru(return_state=True)"]},{"cell_type":"markdown","metadata":{"id":"Zeg0ZNq9F3Hn"},"source":["# Bidirectional GRU\n","\n","- cell state 가 없는 것 외에 LSTM 과 동일"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rrKrFJ3BF3Hn","outputId":"b38415f2-dad1-4636-fb6b-5cb954311b38"},"outputs":[{"name":"stdout","output_type":"stream","text":["---- 순방향, 역방향이 concatenate 된 many-to-one output\n","o : (2, 6)\n","\n","---- 순방향, 역방향이 concatenate 된 many-to-many output\n","o : (2, 5, 6)\n","\n","---- 순방향, 역방향이 concatenate 된 sequence-to-vector output\n","o : (2, 6)\n","h1 : (2, 3)\n","h2 : (2, 3)\n"]}],"source":["def bi_gru(return_sequences=False, return_state=False):\n","    inp = Input(shape=(T, D))\n","    out = Bidirectional(\n","            GRU(U, return_state=return_state, return_sequences=return_sequences))(inp)\n","\n","    model = Model(inputs=inp, outputs=out)\n","    if return_state:\n","        o, h1, h2 = model.predict(X)\n","        print(\"o :\", o.shape)\n","        print(\"h1 :\", h1.shape)\n","        print(\"h2 :\", h2.shape)\n","    else:\n","        o = model.predict(X)\n","        print(\"o :\", o.shape)\n","\n","print(\"---- 순방향, 역방향이 concatenate 된 many-to-one output\")\n","bi_gru(return_sequences=False, return_state=False)\n","print()\n","print(\"---- 순방향, 역방향이 concatenate 된 many-to-many output\")\n","bi_gru(return_sequences=True)\n","print()\n","print(\"---- 순방향, 역방향이 concatenate 된 sequence-to-vector output\")\n","bi_gru(return_state=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4RUEZBhKIlP2"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}